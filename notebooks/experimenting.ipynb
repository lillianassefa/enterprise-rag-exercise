{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/lillian/Documents/TenAcademy/enterprise-rag-exercise/backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrival import file_reader\n",
    "from retrival import test_contextualized_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pinecone'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpinecone\u001b[39;00m\n\u001b[1;32m      4\u001b[0m pinecone\u001b[38;5;241m.\u001b[39minit(\n\u001b[1;32m      5\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPINECONE_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3306f52a-a64a-46dd-b81a-0d073fb5a072\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     environment\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPINECONE_ENVIRONMENT\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgcp-starter\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pinecone'"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY') or '3306f52a-a64a-46dd-b81a-0d073fb5a072',\n",
    "    environment=os.environ.get('PINECONE_ENVIRONMENT') or 'gcp-starter'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pinecone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      3\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama-2-rag\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpinecone\u001b[49m\u001b[38;5;241m.\u001b[39mlist_indexes():\n\u001b[1;32m      6\u001b[0m     pinecone\u001b[38;5;241m.\u001b[39mcreate_index(\n\u001b[1;32m      7\u001b[0m         index_name,\n\u001b[1;32m      8\u001b[0m         dimension\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1536\u001b[39m,\n\u001b[1;32m      9\u001b[0m         metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# wait for index to finish initialization\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pinecone' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "index_name = 'llama-2-rag'\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,\n",
    "        metric='cosine'\n",
    "    )\n",
    "    # wait for index to finish initialization\n",
    "    while not pinecone.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pinecone.Index(index_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.04838,\n",
       " 'namespaces': {'': {'vector_count': 4838}},\n",
       " 'total_vector_count': 4838}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_message = file_reader(\"/home/lillian/Documents/TenAcademy/enterprise-rag-exercise/backend/context.txt\")\n",
    "document = context_message.split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vector = vectorizer.fit_transform(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 413)\t0.7266547071407753\n",
      "  (0, 99)\t0.6870028650523621\n",
      "  (1, 138)\t0.10080123133878717\n",
      "  (1, 583)\t0.10855373183519164\n",
      "  (1, 347)\t0.07778124866569268\n",
      "  (1, 10)\t0.10080123133878717\n",
      "  (1, 579)\t0.10855373183519164\n",
      "  (1, 672)\t0.09530074470038043\n",
      "  (1, 351)\t0.10855373183519164\n",
      "  (1, 193)\t0.10855373183519164\n",
      "  (1, 404)\t0.10855373183519164\n",
      "  (1, 236)\t0.09530074470038043\n",
      "  (1, 115)\t0.10855373183519164\n",
      "  (1, 183)\t0.10855373183519164\n",
      "  (1, 55)\t0.17509648840795186\n",
      "  (1, 15)\t0.10855373183519164\n",
      "  (1, 240)\t0.10855373183519164\n",
      "  (1, 168)\t0.10855373183519164\n",
      "  (1, 205)\t0.10080123133878717\n",
      "  (1, 421)\t0.10855373183519164\n",
      "  (1, 173)\t0.10080123133878717\n",
      "  (1, 219)\t0.10855373183519164\n",
      "  (1, 539)\t0.10855373183519164\n",
      "  (1, 450)\t0.10855373183519164\n",
      "  (1, 455)\t0.10855373183519164\n",
      "  :\t:\n",
      "  (207, 490)\t0.2995873471089458\n",
      "  (207, 385)\t0.2995873471089458\n",
      "  (207, 237)\t0.2995873471089458\n",
      "  (207, 225)\t0.2995873471089458\n",
      "  (207, 460)\t0.2995873471089458\n",
      "  (207, 522)\t0.2630116606736323\n",
      "  (207, 93)\t0.27819194210615195\n",
      "  (207, 446)\t0.27819194210615195\n",
      "  (207, 689)\t0.20963194741657235\n",
      "  (207, 674)\t0.2630116606736323\n",
      "  (207, 595)\t0.2630116606736323\n",
      "  (207, 103)\t0.2512369196203142\n",
      "  (207, 427)\t0.20963194741657235\n",
      "  (207, 627)\t0.13769367536128177\n",
      "  (207, 257)\t0.13769367536128177\n",
      "  (208, 246)\t1.0\n",
      "  (209, 132)\t0.4079616847988938\n",
      "  (209, 689)\t0.3074201280175999\n",
      "  (209, 282)\t0.34239579424133054\n",
      "  (209, 246)\t0.35432433445776546\n",
      "  (209, 20)\t0.4079616847988938\n",
      "  (209, 676)\t0.3320628227042403\n",
      "  (209, 509)\t0.3684328030352431\n",
      "  (209, 627)\t0.20192441003595202\n",
      "  (209, 307)\t0.2075207520118581\n"
     ]
    }
   ],
   "source": [
    "print(context_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_open_params(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,):\n",
    "    openai_params = {}    \n",
    "\n",
    "    openai_params['model'] = model\n",
    "    openai_params['temperature'] = temperature\n",
    "    openai_params['max_tokens'] = max_tokens\n",
    "    openai_params['top_p'] = top_p\n",
    "    openai_params['frequency_penalty'] = frequency_penalty\n",
    "    openai_params['presence_penalty'] = presence_penalty\n",
    "    return openai_params\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import IPython\n",
    "\n",
    "def get_completion(params, messages):\n",
    "    \"\"\" GET completion from openai api\"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model = params['model'],\n",
    "        messages = messages,\n",
    "        temperature = params['temperature'],\n",
    "        max_tokens = params['max_tokens'],\n",
    "        top_p = params['top_p'],\n",
    "        frequency_penalty = params['frequency_penalty'],\n",
    "        presence_penalty = params['presence_penalty'],\n",
    "    )\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#PROMPTING EXPERIMENT\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#few-shot prompts\u001b[39;00m\n\u001b[1;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m [{\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m , \n\u001b[1;32m      5\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mThe odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124mThe odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124mA:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m}]\n\u001b[0;32m---> 20\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m messages \u001b[38;5;241m=\u001b[39m prompt,\n\u001b[1;32m     23\u001b[0m temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m     24\u001b[0m max_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m     25\u001b[0m top_p \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     26\u001b[0m frequency_penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \n\u001b[1;32m     27\u001b[0m IPython\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mMarkdown(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'chat'"
     ]
    }
   ],
   "source": [
    "#PROMPTING EXPERIMENT\n",
    "#few-shot prompts\n",
    "prompt = [{\n",
    "  \"role\": \"user\" , \n",
    "  \"content\":\"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: The answer is False.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.\n",
    "A: The answer is True.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.\n",
    "A: The answer is True.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
    "A: The answer is False.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
    "A:\"\"\"}]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "model = \"gpt-3.5-turbo\",\n",
    "messages = prompt,\n",
    "temperature = 1.0,\n",
    "max_tokens = 256,\n",
    "top_p =1,\n",
    "frequency_penalty = 0) \n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = set_open_params()\n",
    "prompt = \"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
    "A:\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Step 1: You bought 10 apples.\n",
       "Step 2: You gave 2 apples to the neighbor, so you have 10 - 2 = 8 apples remaining.\n",
       "Step 3: You gave 2 more apples to the repairman, so you have 8 - 2 = 6 apples remaining.\n",
       "Step 4: You bought 5 more apples, so you have 6 + 5 = 11 apples.\n",
       "Step 5: You ate 1 apple, so you have 11 - 1 = 10 apples remaining.\n",
       "\n",
       "Therefore, you have 10 apples remaining."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?\n",
    "\n",
    "Let's think step by step.\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': [{'class': 'Document',\n",
       "   'description': 'Represents a document with content and vector representation.',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'generative-openai': {},\n",
       "    'text2vec-openai': {'baseURL': 'https://api.openai.com',\n",
       "     'model': 'ada',\n",
       "     'modelVersion': '002',\n",
       "     'type': 'text',\n",
       "     'vectorizeClassName': True}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['text'],\n",
       "     'description': 'The content of the document.',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'content',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'The category',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'category',\n",
       "     'tokenization': 'word'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-openai'},\n",
       "  {'class': 'Article',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'text2vec-cohere': {'model': 'embed-multilingual-v2.0',\n",
       "     'vectorizeClassName': True}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['text'],\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-cohere': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'title',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['text'],\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-cohere': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'body',\n",
       "     'tokenization': 'word'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-cohere'}]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weaviate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "weaviate_api_key = os.getenv(\"WEAVIATE_API_kEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = weaviate.Client(\n",
    "    url=\"https://precision-rag-ov8u665q.weaviate.network\", \n",
    "    auth_client_secret=weaviate.AuthApiKey(api_key= weaviate_api_key),\n",
    "     additional_headers={\n",
    "        \"X-OpenAI-Api-Key\": openai_api_key  \n",
    "    }\n",
    "      )\n",
    "\n",
    "client.schema.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_obj = {\n",
    "    \"class\": \"Document\",\n",
    "    \"description\" : \"Represents a document with content and vector representation.\",\n",
    "     \"properties\": [\n",
    "           {\n",
    "               \"name\": \"content\",\n",
    "               \"dataType\": [\"text\"],\n",
    "               \"description\": \"The content of the document.\"\n",
    "           },\n",
    "           {\n",
    "               \"name\": \"category\",\n",
    "               \"dataType\": [\"text\"],\n",
    "               \"description\": \"The category\"\n",
    "           }\n",
    "     ],\n",
    "    \"vectorizer\": \"text2vec-openai\",  \n",
    "    \"moduleConfig\": {\n",
    "        \"text2vec-openai\": {},\n",
    "        \"generative-openai\": {} \n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "client.schema.create_class(class_obj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': [{'class': 'Document', 'description': 'Represents a document with content and vector representation.', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'moduleConfig': {'generative-openai': {}, 'text2vec-openai': {'baseURL': 'https://api.openai.com', 'model': 'ada', 'modelVersion': '002', 'type': 'text', 'vectorizeClassName': True}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'description': 'The content of the document.', 'indexFilterable': True, 'indexSearchable': True, 'moduleConfig': {'text2vec-openai': {'skip': False, 'vectorizePropertyName': False}}, 'name': 'content', 'tokenization': 'word'}, {'dataType': ['text'], 'description': 'The category', 'indexFilterable': True, 'indexSearchable': True, 'moduleConfig': {'text2vec-openai': {'skip': False, 'vectorizePropertyName': False}}, 'name': 'category', 'tokenization': 'word'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'text2vec-openai'}, {'class': 'Article', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'moduleConfig': {'text2vec-cohere': {'model': 'embed-multilingual-v2.0', 'vectorizeClassName': True}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'moduleConfig': {'text2vec-cohere': {'skip': False, 'vectorizePropertyName': False}}, 'name': 'title', 'tokenization': 'word'}, {'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'moduleConfig': {'text2vec-cohere': {'skip': False, 'vectorizePropertyName': False}}, 'name': 'body', 'tokenization': 'word'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'text2vec-cohere'}]}\n"
     ]
    }
   ],
   "source": [
    "schema  = client.schema.get()\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.schema.delete_class(\"Document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_object = {\n",
    "    \n",
    "    \"class\": \"Article\",\n",
    "    \"vectorizer\": \"text2vec-cohere\",\n",
    "    \"moduleConfig\": {\n",
    "        \"text2vec-cohere\": {\n",
    "            \"model\": \"embed-multilingual-v2.0\",\n",
    "        },\n",
    "    },\n",
    "    \"properties\": [\n",
    "        {\n",
    "            \"name\": \"title\",\n",
    "            \"dataType\": [\"text\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"body\",\n",
    "            \"dataType\": [\"text\"]\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "client.schema.create_class(class_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"context.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    document_content = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object = {\n",
    "    \"class\": \"Document\", \n",
    "    \"properties\": {\n",
    "        \"text\": document_content\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.util import generate_uuid5\n",
    "\n",
    "data_object[\"uuid\"]= generate_uuid5(data_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cb9aac85-1d85-4b0f-9a9c-f820cc76ff9c'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.data_object.create(class_name=\"Document\",data_object= data_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "No 'properties' or 'additional properties' specified to be returned. At least one should be included.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query_result \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDocument\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m data_objects \u001b[38;5;241m=\u001b[39m query_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data_objects:\n",
      "File \u001b[0;32m~/anaconda3/envs/week6/lib/python3.12/site-packages/weaviate/gql/get.py:1905\u001b[0m, in \u001b[0;36mGetBuilder.do\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/week6/lib/python3.12/site-packages/weaviate/gql/filter.py:118\u001b[0m, in \u001b[0;36mGraphQL.do\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m    103\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    Builds and runs the query.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m        If weaviate reports a none OK status.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mpost(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/graphql\u001b[39m\u001b[38;5;124m\"\u001b[39m, weaviate_object\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query})\n",
      "File \u001b[0;32m~/anaconda3/envs/week6/lib/python3.12/site-packages/weaviate/gql/get.py:1785\u001b[0m, in \u001b[0;36mGetBuilder.build\u001b[0;34m(self, wrap_get)\u001b[0m\n\u001b[1;32m   1782\u001b[0m additional_props \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_additional_to_str()\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (additional_props \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_properties):\n\u001b[0;32m-> 1785\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1786\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madditional properties\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m specified to be returned. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1787\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one should be included.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1788\u001b[0m     )\n\u001b[1;32m   1790\u001b[0m properties \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_properties) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_additional_to_str()\n\u001b[1;32m   1791\u001b[0m query \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m properties \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: No 'properties' or 'additional properties' specified to be returned. At least one should be included."
     ]
    }
   ],
   "source": [
    "query_result = client.query.get(class_name=\"Document\").do()\n",
    "\n",
    "data_objects = query_result[\"data\"][\"Get\"][\"Document\"]\n",
    "for item in data_objects:\n",
    "    text_property = item[\"text\"]\n",
    "    print(f\"Text: {text_property}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
